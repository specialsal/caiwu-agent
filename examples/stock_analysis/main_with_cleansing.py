import asyncio
import pathlib
import re
import os
from typing import Optional
import argparse

from utu.agents import OrchestraAgent
from utu.config import ConfigLoader
from utu.utils.agents_utils import AgentsUtils


async def main():
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description="æ•°æ®æ¸…æ´—è´¢æŠ¥åˆ†ææ™ºèƒ½ä½“ - æ”¯æŒä¸­æ–‡æ•°æ®å¤„ç†")
    parser.add_argument("--stream", action="store_true", help="å¯ç”¨æµå¼è¾“å‡º")
    args = parser.parse_args()
    
    # æ£€æŸ¥æ˜¯å¦è®¾ç½®äº†å¿…è¦çš„ç¯å¢ƒå˜é‡
    llm_type = os.environ.get("UTU_LLM_TYPE")
    llm_model = os.environ.get("UTU_LLM_MODEL")
    llm_api_key = os.environ.get("UTU_LLM_API_KEY")
    llm_base_url = os.environ.get("UTU_LLM_BASE_URL")
    
    if not all([llm_type, llm_model, llm_api_key, llm_base_url]):
        print("è­¦å‘Š: æœªè®¾ç½®å®Œæ•´çš„LLMç¯å¢ƒå˜é‡")
        print("è¯·ç¡®ä¿è®¾ç½®äº†ä»¥ä¸‹ç¯å¢ƒå˜é‡:")
        print("  - UTU_LLM_TYPE")
        print("  - UTU_LLM_MODEL")
        print("  - UTU_LLM_API_KEY")
        print("  - UTU_LLM_BASE_URL")
        print()

    # è®¾ç½®æ•°æ®æ¸…æ´—é…ç½®
    print("ğŸ§¹ åŠ è½½æ•°æ®æ¸…æ´—æ™ºèƒ½ä½“é…ç½®...")
    try:
        config = ConfigLoader.load_agent_config("examples/stock_analysis_final_with_cleansing")
        print("âœ… æ•°æ®æ¸…æ´—é…ç½®åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {str(e)}")
        return
    
    config.planner_config["examples_path"] = pathlib.Path(__file__).parent / "stock_analysis_examples.json"
    
    # Setup workspace for stock analysis
    workspace_path = pathlib.Path(__file__).parent / "stock_analysis_workspace"
    workspace_path.mkdir(exist_ok=True)
    
    print(f"ğŸ“ ä½¿ç”¨å·¥ä½œç›®å½•: {workspace_path}")
    
    # Initialize the agent
    try:
        runner = OrchestraAgent(config)
        await runner.build()
        print("âœ… æ™ºèƒ½ä½“åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ™ºèƒ½ä½“åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return

    # æ•°æ®æ¸…æ´—ä¸“ç”¨æµ‹è¯•æŸ¥è¯¢
    cleansing_example_queries = [
        {
            "description": "ä¸­æ–‡è´¢åŠ¡æ•°æ®æ¸…æ´—åˆ†æ",
            "query": "åˆ†ææµ‹è¯•å…¬å¸çš„è´¢åŠ¡æ•°æ®ï¼Œåˆ©æ¶¦è¡¨æ˜¾ç¤ºè¥ä¸šæ”¶å…¥573.88äº¿å…ƒï¼Œå‡€åˆ©æ¶¦11.04äº¿å…ƒï¼Œå†å²æ•°æ®åŒ…å«2025å¹´å’Œ2024å¹´çš„å®Œæ•´è´¢åŠ¡è¡¨ç°ï¼Œéœ€è¦è¯†åˆ«å’Œæ¸…æ´—ä¸­æ–‡é”®åæ•°æ®",
            "features": ["ä¸­æ–‡é”®åè¯†åˆ«", "å†å²æ•°æ®è§£æ", "æ•°æ®è´¨é‡è¯„ä¼°", "æ ‡å‡†åŒ–è¾“å‡º"]
        },
        {
            "description": "å¤æ‚ä¸­æ–‡æ•°æ®ç»“æ„å¤„ç†",
            "query": "åˆ†ææŸå…¬å¸çš„å®Œæ•´è´¢åŠ¡æŠ¥è¡¨ï¼ŒåŒ…å«åˆ©æ¶¦è¡¨ï¼ˆè¥ä¸šæ”¶å…¥ã€è¥ä¸šæˆæœ¬ã€å‡€åˆ©æ¶¦ï¼‰ã€èµ„äº§è´Ÿå€ºè¡¨ï¼ˆæ€»èµ„äº§ã€æ€»è´Ÿå€ºã€æ‰€æœ‰è€…æƒç›Šï¼‰ã€ç°é‡‘æµé‡è¡¨ï¼Œå†å²æ•°æ®ä»2022å¹´åˆ°2025å¹´çš„è¯¦ç»†è´¢åŠ¡æŒ‡æ ‡ï¼Œéœ€è¦æ™ºèƒ½æ¸…æ´—å’Œæ ‡å‡†åŒ–",
            "features": ["å®Œæ•´æŠ¥è¡¨è§£æ", "å¤šå¹´å†å²æ•°æ®", "æ™ºèƒ½å­—æ®µæ˜ å°„", "æ•°æ®æ ¼å¼è½¬æ¢"]
        },
        {
            "description": "é—®é¢˜æ•°æ®ä¿®å¤æµ‹è¯•",
            "query": "åˆ†æå­˜åœ¨é—®é¢˜çš„è´¢åŠ¡æ•°æ®ï¼ŒåŒ…å«ç¼ºå¤±å­—æ®µã€å¼‚å¸¸å€¼ã€æ ¼å¼ä¸ä¸€è‡´ç­‰é—®é¢˜ï¼Œæµ‹è¯•æ•°æ®æ¸…æ´—æ™ºèƒ½ä½“çš„é”™è¯¯æ£€æµ‹å’Œè‡ªåŠ¨ä¿®å¤åŠŸèƒ½",
            "features": ["é”™è¯¯æ£€æµ‹", "è‡ªåŠ¨ä¿®å¤", "æ•°æ®éªŒè¯", "è´¨é‡æå‡"]
        },
        {
            "description": "å®é™…è‚¡ç¥¨åˆ†æ",
            "query": "åˆ†æé™•è¥¿å»ºå·¥(600248.SH)çš„æœ€æ–°è´¢æŠ¥æ•°æ®ï¼ŒéªŒè¯æ•°æ®æ¸…æ´—åŠŸèƒ½æ˜¯å¦æ­£ç¡®å¤„ç†ä¸­æ–‡é”®åå’Œå†å²æ•°æ®ï¼Œç”Ÿæˆæ ‡å‡†åŒ–è´¢åŠ¡åˆ†ææŠ¥å‘Š",
            "features": ["çœŸå®æ•°æ®æµ‹è¯•", "ä¸­æ–‡å¤„ç†éªŒè¯", "æ ‡å‡†åŒ–åˆ†æ", "å¯¹æ¯”è¯„ä¼°"]
        },
        {
            "description": "å¤šæ ¼å¼æ•°æ®èåˆ",
            "query": "åˆ†æåŒ…å«ä¸­è‹±æ–‡æ··åˆã€æ ¼å¼ä¸ç»Ÿä¸€çš„å¤æ‚è´¢åŠ¡æ•°æ®ï¼Œæµ‹è¯•æ•°æ®æ¸…æ´—æ™ºèƒ½ä½“çš„å¤šæ ¼å¼å¤„ç†èƒ½åŠ›å’Œæ™ºèƒ½è½¬æ¢åŠŸèƒ½",
            "features": ["å¤šæ ¼å¼å¤„ç†", "æ™ºèƒ½è¯†åˆ«", "æ ¼å¼è½¬æ¢", "æ•°æ®èåˆ"]
        }
    ]

    print("=== ğŸš€ æ•°æ®æ¸…æ´—è´¢æŠ¥åˆ†ææ™ºèƒ½ä½“ ===")
    print("ğŸ’¡ å¢å¼ºæ™ºèƒ½ä½“åä½œ: DataAgent â†’ DataCleanserAgent â†’ DataAnalysisAgent â†’ FinancialAnalysisAgent â†’ ChartGeneratorAgent â†’ ReportAgent")
    print("ğŸ§¹ æ ¸å¿ƒåŠŸèƒ½: ä¸­æ–‡æ•°æ®è¯†åˆ« â†’ æ™ºèƒ½å­—æ®µæ˜ å°„ â†’ æ•°æ®è´¨é‡è¯„ä¼° â†’ é”™è¯¯ä¿®å¤ â†’ æ ‡å‡†åŒ–è¾“å‡º")
    print("\nğŸ“Š æ•°æ®æ¸…æ´—æµ‹è¯•æ¡ˆä¾‹:")
    for i, item in enumerate(cleansing_example_queries, 1):
        print(f"{i}. ğŸ¯ {item['description']}")
        print(f"   ğŸ“ˆ {item['query']}")
        print(f"   âœ¨ æ•°æ®æ¸…æ´—åŠŸèƒ½: {', '.join(item['features'])}")
        print()

    try:
        user_input = input("è¯·é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹ (è¾“å…¥æ•°å­— 1-5) æˆ–è¾“å…¥è‡ªå®šä¹‰ä¸­æ–‡æ•°æ®åˆ†æ (æŒ‰qé€€å‡º): ").strip()
        if user_input.lower() == 'q':
            print("\nç¨‹åºå·²é€€å‡ºã€‚")
            return
    except EOFError:
        print("\nç¨‹åºå·²ä¼˜é›…é€€å‡ºã€‚")
        return

    if user_input.isdigit() and 1 <= int(user_input) <= len(cleansing_example_queries):
        selected_item = cleansing_example_queries[int(user_input) - 1]
        question = selected_item['query']
        print(f"\nğŸ¯ é€‰æ‹©æµ‹è¯•: {selected_item['description']}")
        print(f"ğŸ§¹ æ•°æ®æ¸…æ´—é‡ç‚¹: {', '.join(selected_item['features'])}")
    else:
        question = user_input
        print(f"\nğŸ” è‡ªå®šä¹‰æ•°æ®æ¸…æ´—åˆ†æ: {question}")

    print(f"\nâš¡ å¯åŠ¨æ•°æ®æ¸…æ´—åˆ†ææµç¨‹...")
    print(f"ğŸ¤– å¢å¼ºæ™ºèƒ½ä½“ç»„åˆ: DataAgent â†’ DataCleanserAgent â†’ DataAnalysisAgent â†’ FinancialAnalysisAgent â†’ ChartGeneratorAgent â†’ ReportAgent")
    print(f"ğŸ§¹ æ•°æ®æ¸…æ´—æ­¥éª¤: ä¸­æ–‡è¯†åˆ« â†’ å­—æ®µæ˜ å°„ â†’ è´¨é‡è¯„ä¼° â†’ é”™è¯¯ä¿®å¤ â†’ æ ‡å‡†åŒ–è¾“å‡º")
    
    # Run the analysis with or without streaming
    try:
        if args.stream:
            print("ğŸŒŠ ä½¿ç”¨æµå¼è¾“å‡º...")
            result = runner.run_streamed(question)
            await AgentsUtils.print_stream_events(result.stream_events())
            final_output = result.final_output
        else:
            print("ğŸ“‹ ä½¿ç”¨æ ‡å‡†è¾“å‡º...")
            result = await runner.run(question)
            final_output = result.final_output

        # Extract and save the result
        final_output = result.final_output
        
        # æ”¹è¿›çš„HTMLæ£€æµ‹å’Œå¤„ç†é€»è¾‘
        def is_html_content(content):
            """æ›´å‡†ç¡®çš„HTMLå†…å®¹æ£€æµ‹"""
            html_indicators = [
                "<html", "<div", "<span", "<p>", "<h1", "<h2", "<h3",
                "<table", "<ul>", "<ol>", "<strong>", "<em>", "<br>", "<hr",
                "<style>", "<script>", "<link>", "<meta"
            ]
            content_lower = content.lower()
            return any(indicator in content_lower for indicator in html_indicators)

        def format_html_content(content):
            """æ ¼å¼åŒ–HTMLå†…å®¹ä¸ºå®Œæ•´æ–‡æ¡£"""
            # æå–HTMLå†…å®¹
            if "```html" in content:
                match = re.search(r"```html(.*?)```", content, re.DOTALL)
                if match:
                    content = match.group(1).strip()

            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ å®Œæ•´HTMLç»“æ„
            if not content.strip().startswith("<!DOCTYPE") and not content.strip().startswith("<html"):
                # æ·»åŠ åŸºæœ¬HTMLç»“æ„å’Œæ ·å¼
                formatted_html = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ•°æ®æ¸…æ´—è´¢åŠ¡åˆ†ææŠ¥å‘Š</title>
    <style>
        body {{
            font-family: "Microsoft YaHei", "PingFang SC", "Hiragino Sans GB", Arial, sans-serif;
            margin: 20px;
            line-height: 1.6;
            color: #333;
            background-color: #fff;
        }}
        h1, h2, h3 {{
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
            margin-top: 30px;
        }}
        h1 {{ font-size: 28px; text-align: center; color: #2980b9; }}
        h2 {{ font-size: 22px; }}
        h3 {{ font-size: 18px; }}
        table {{
            border-collapse: collapse;
            width: 100%;
            margin: 20px 0;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        th, td {{
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }}
        th {{
            background-color: #3498db;
            color: white;
            font-weight: bold;
        }}
        tr:nth-child(even) {{ background-color: #f2f2f2; }}
        .metric {{
            background-color: #ecf0f1;
            padding: 15px;
            margin: 10px 0;
            border-radius: 5px;
            border-left: 4px solid #3498db;
        }}
        .positive {{ color: #27ae60; font-weight: bold; }}
        .negative {{ color: #e74c3c; font-weight: bold; }}
        .neutral {{ color: #f39c12; font-weight: bold; }}
        .cleansing-highlight {{
            background-color: #e8f5e8;
            padding: 15px;
            margin: 10px 0;
            border-radius: 5px;
            border-left: 4px solid #27ae60;
        }}
        blockquote {{
            background-color: #f9f9f9;
            border-left: 4px solid #3498db;
            margin: 20px 0;
            padding: 15px;
        }}
        ul, ol {{ margin: 15px 0; padding-left: 30px; }}
        li {{ margin: 5px 0; }}
        .highlight {{
            background-color: #fff3cd;
            padding: 10px;
            border-radius: 4px;
            border: 1px solid #ffeaa7;
        }}
    </style>
</head>
<body>
{content}
</body>
</html>"""
                return formatted_html

            return content

        # åˆ†ææŠ¥å‘Šç±»å‹å’Œç»Ÿè®¡ä¿¡æ¯
        def analyze_report_type(content):
            """åˆ†ææŠ¥å‘Šç±»å‹"""
            company_count = len(re.findall(r'\d{6}\.(SH|SZ)', content))
            if company_count == 0:
                return "å•å…¬å¸æ·±åº¦åˆ†æ"
            elif company_count == 1:
                return "å•å…¬å¸è´¢åŠ¡åˆ†æ"
            else:
                return f"å¤šå…¬å¸å¯¹æ¯”åˆ†æ({company_count}å®¶)"

        def detect_cleansing_features(content):
            """æ£€æµ‹æ•°æ®æ¸…æ´—ç‰¹æ€§"""
            features = []
            cleansing_indicators = [
                ("æ•°æ®æ¸…æ´—", ["æ¸…æ´—", "æ ‡å‡†åŒ–", "è½¬æ¢", "æ˜ å°„"]),
                ("ä¸­æ–‡è¯†åˆ«", ["ä¸­æ–‡", "é”®å", "å­—æ®µ", "ä¸­æ–‡é”®"]),
                ("å†å²æ•°æ®", ["å†å²æ•°æ®", "å¹´ä»½", "2025", "2024", "2023"]),
                ("è´¨é‡è¯„ä¼°", ["è´¨é‡", "è¯„ä¼°", "è¯„åˆ†", "éªŒè¯"]),
                ("é”™è¯¯ä¿®å¤", ["ä¿®å¤", "é”™è¯¯", "å¼‚å¸¸", "ç¼ºå¤±"]),
                ("æ ¼å¼è½¬æ¢", ["æ ¼å¼", "è½¬æ¢", "æ ‡å‡†åŒ–", "è‹±æ–‡"])
            ]
            
            for feature, keywords in cleansing_indicators:
                if any(keyword in content for keyword in keywords):
                    features.append(feature)
            
            return features if features else ["ç»¼åˆåˆ†æ"]

        # æ£€æµ‹å†…å®¹ç±»å‹å¹¶ä¿å­˜
        report_type = analyze_report_type(final_output)
        cleansing_features = detect_cleansing_features(final_output)

        print(f"\nğŸ“‹ æŠ¥å‘Šç±»å‹: {report_type}")
        print(f"ğŸ§¹ æ•°æ®æ¸…æ´—åŠŸèƒ½: {', '.join(cleansing_features)}")
        print(f"ğŸ“Š å†…å®¹é•¿åº¦: {len(final_output):,} å­—ç¬¦")

        if is_html_content(final_output):
            # æ ¼å¼åŒ–HTMLå†…å®¹
            formatted_html = format_html_content(final_output)

            report_path = workspace_path / "data_cleansing_analysis_report.html"
            with open(report_path, "w", encoding="utf-8") as f:
                f.write(formatted_html)

            file_size = report_path.stat().st_size
            print(f"âœ… HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {report_path.name} ({file_size:,} bytes)")
            print(f"ğŸŒ åŒ…å«æ•°æ®æ¸…æ´—é«˜äº®æ ·å¼ï¼Œå®Œç¾æ”¯æŒä¸­æ–‡å†…å®¹")
        else:
            # åŒæ—¶ä¿å­˜TXTå’ŒHTMLæ ¼å¼
            txt_report_path = workspace_path / "data_cleansing_analysis_report.txt"
            html_report_path = workspace_path / "data_cleansing_analysis_report.html"

            # ä¿å­˜æ–‡æœ¬æ ¼å¼
            with open(txt_report_path, "w", encoding="utf-8") as f:
                f.write(f"æ•°æ®æ¸…æ´—è´¢åŠ¡åˆ†ææŠ¥å‘Š\n")
                f.write(f"åˆ†ææ—¶é—´: {asyncio.get_event_loop().time()}\n")
                f.write(f"æ•°æ®æ¸…æ´—åŠŸèƒ½: {', '.join(cleansing_features)}\n")
                f.write(f"\nåˆ†æç»“æœ:\n")
                f.write(final_output)
            txt_size = txt_report_path.stat().st_size
            print(f"ğŸ“ æ–‡æœ¬æŠ¥å‘Š: {txt_report_path.name} ({txt_size:,} bytes)")

            # å°†æ–‡æœ¬å†…å®¹è½¬æ¢ä¸ºHTMLæ ¼å¼
            cleansing_highlight = f"<div class='cleansing-highlight'>æ•°æ®æ¸…æ´—åŠŸèƒ½: {', '.join(cleansing_features)}</div>\n\n"
            basic_html = format_html_content(cleansing_highlight +
                                       final_output.replace('\n', '<br>\n').replace('**', '<strong>').replace('**', '</strong>'))

            with open(html_report_path, "w", encoding="utf-8") as f:
                f.write(basic_html)
            html_size = html_report_path.stat().st_size
            print(f"ğŸŒ HTMLç‰ˆæœ¬: {html_report_path.name} ({html_size:,} bytes)")

        # åˆ†æä»»åŠ¡æ‰§è¡Œæƒ…å†µ
        if hasattr(result, 'task_records'):
            task_count = len(result.task_records)
            successful_tasks = sum(1 for task in result.task_records if hasattr(task, 'output') and task.output)
            
            # æ£€æŸ¥DataCleanserAgentæ‰§è¡Œæƒ…å†µ
            cleanser_tasks = [task for task in result.task_records if 'DataCleanser' in str(task)]
            cleanser_count = len(cleanser_tasks)
            
            print(f"\nğŸ¤– ä»»åŠ¡æ‰§è¡Œç»Ÿè®¡:")
            print(f"  æ€»ä»»åŠ¡æ•°: {task_count}")
            print(f"  æˆåŠŸä»»åŠ¡: {successful_tasks}")
            print(f"  æ•°æ®æ¸…æ´—ä»»åŠ¡: {cleanser_count}")
            print(f"  æˆåŠŸç‡: {successful_tasks/task_count*100:.1f}%" if task_count > 0 else "  æˆåŠŸç‡: N/A")
            
            if cleanser_tasks:
                print(f"  âœ… DataCleanserAgentæ­£å¸¸æ‰§è¡Œ ({cleanser_count}ä¸ªä»»åŠ¡)")
            else:
                print(f"  âš ï¸ æœªæ£€æµ‹åˆ°DataCleanserAgentæ‰§è¡Œ")
            
            # æ£€æŸ¥æ•°æ®æ¸…æ´—æ•ˆæœ
            output_str = str(final_output).lower()
            chinese_indicators = ["åˆ©æ¶¦è¡¨", "èµ„äº§è´Ÿå€ºè¡¨", "ç°é‡‘æµé‡è¡¨", "è¥ä¸šæ”¶å…¥", "å‡€åˆ©æ¶¦"]
            chinese_found = [ind for ind in chinese_indicators if ind in final_output]
            
            if chinese_found:
                print(f"  ğŸˆ¯ ä¸­æ–‡æ•°æ®å¤„ç†: {', '.join(chinese_found)}")
            
            # æ£€æŸ¥æ ‡å‡†åŒ–è¾“å‡º
            english_indicators = ["income_statement", "balance_sheet", "cash_flow", "revenue", "net_profit"]
            english_found = [ind for ind in english_indicators if ind in output_str]
            
            if english_found:
                print(f"  ğŸ”„ æ ‡å‡†åŒ–è¾“å‡º: {', '.join(english_found)}")

        print(f"\nğŸ‰ æ•°æ®æ¸…æ´—åˆ†æå®Œæˆ!")
        print(f"ğŸ“ å·¥ä½œç›®å½•: {workspace_path.absolute()}")
        print(f"ğŸ§¹ æ•°æ®æ¸…æ´—ç‰¹æ€§: {len(cleansing_features)}é¡¹åŠŸèƒ½åº”ç”¨")

        # List generated files with details
        generated_files = list(workspace_path.glob("*"))
        if generated_files:
            print(f"\nğŸ“„ ç”Ÿæˆçš„æ–‡ä»¶ ({len(generated_files)} ä¸ª):")
            for file in sorted(generated_files):
                size = file.stat().st_size
                if file.suffix.lower() in ['.html', '.htm']:
                    print(f"  ğŸŒ {file.name} ({size:,} bytes) - HTMLæŠ¥å‘Š")
                elif file.suffix.lower() == '.pdf':
                    print(f"  ğŸ“‹ {file.name} ({size:,} bytes) - PDFæŠ¥å‘Š")
                elif file.suffix.lower() in ['.png', '.jpg', '.jpeg']:
                    print(f"  ğŸ“ˆ {file.name} ({size:,} bytes) - å›¾è¡¨æ–‡ä»¶")
                else:
                    print(f"  ğŸ“„ {file.name} ({size:,} bytes)")

        print(f"\nğŸ’¡ æ•°æ®æ¸…æ´—éªŒè¯:")
        print(f"  1. åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ HTML æŸ¥çœ‹æ ¼å¼åŒ–æŠ¥å‘Š")
        print(f"  2. æ£€æŸ¥æ˜¯å¦æ­£ç¡®å¤„ç†äº†ä¸­æ–‡é”®åæ•°æ®")
        print(f"  3. éªŒè¯å†å²æ•°æ®å¹´ä»½è§£æåŠŸèƒ½")
        print(f"  4. ç¡®è®¤æ•°æ®è´¨é‡è¯„ä¼°ç»“æœ")
        print(f"  5. æŸ¥çœ‹æ ‡å‡†åŒ–æ ¼å¼è¾“å‡ºæ•ˆæœ")

    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


def main_web():
    """å¯åŠ¨Webç•Œé¢"""
    import argparse
    from utu.ui import ExampleConfig
    from utu.ui.webui_chatbot import WebUIChatbot
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    env_and_args = ExampleConfig()
    
    # è®¾ç½®æ•°æ®æ¸…æ´—é…ç½®
    print("ğŸ§¹ åŠ è½½æ•°æ®æ¸…æ´—æ™ºèƒ½ä½“é…ç½®...")
    try:
        config = ConfigLoader.load_agent_config("examples/stock_analysis_final_with_cleansing")
        print("âœ… æ•°æ®æ¸…æ´—é…ç½®åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {str(e)}")
        return
    
    config.planner_config["examples_path"] = pathlib.Path(__file__).parent / "stock_analysis_examples.json"
    
    workspace_path = pathlib.Path(__file__).parent / "stock_analysis_workspace"
    workspace_path.mkdir(exist_ok=True)
    
    print(f"ğŸ“ ä½¿ç”¨å·¥ä½œç›®å½•: {workspace_path}")
    
    try:
        runner = OrchestraAgent(config)
        example_query = "åˆ†æåŒ…å«ä¸­æ–‡é”®åçš„è´¢åŠ¡æ•°æ®ï¼Œæµ‹è¯•æ•°æ®æ¸…æ´—å’Œæ ‡å‡†åŒ–åŠŸèƒ½"
        
        ui = WebUIChatbot(runner, example_query=example_query)
        # ä½¿ç”¨é»˜è®¤å€¼æˆ–ç¯å¢ƒå˜é‡
        port = int(env_and_args.port) if env_and_args.port else 8848
        ip = env_and_args.ip if env_and_args.ip else "127.0.0.1"
        ui.launch(port=port, ip=ip, autoload=env_and_args.autoload)
        
    except Exception as e:
        print(f"âŒ Webç•Œé¢å¯åŠ¨å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "web":
        try:
            main_web()
        except KeyboardInterrupt:
            print("\nç¨‹åºå·²ä¼˜é›…é€€å‡ºã€‚")
            exit(0)
    else:
        try:
            asyncio.run(main())
        except KeyboardInterrupt:
            print("\nç¨‹åºå·²ä¼˜é›…é€€å‡ºã€‚")
            exit(0)