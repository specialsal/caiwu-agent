#!/usr/bin/env python3
"""
æ•°æ®æ¸…æ´—ç³»ç»Ÿç‹¬ç«‹æµ‹è¯•å¥—ä»¶
å…¨é¢æµ‹è¯•DataCleanserAgentå’Œæ•°æ®å·¥ç¨‹ç»„ä»¶çš„åŠŸèƒ½å’Œæ€§èƒ½
"""

import sys
import os
import json
import asyncio
from pathlib import Path
from typing import Dict, Any, List
import logging
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# æµ‹è¯•æ•°æ®
TEST_DATA_SAMPLES = {
    "chinese_financial_format": {
        "åˆ©æ¶¦è¡¨": {
            "è¥ä¸šæ”¶å…¥": 573.88,
            "å‡€åˆ©æ¶¦": 11.04,
            "è¥ä¸šæˆæœ¬": 552.84,
            "è¥ä¸šåˆ©æ¶¦": 11.04
        },
        "èµ„äº§è´Ÿå€ºè¡¨": {
            "æ€»èµ„äº§": 3472.98,
            "æ€»è´Ÿå€º": 3081.02,
            "æ‰€æœ‰è€…æƒç›Š": 391.96,
            "æµåŠ¨èµ„äº§": 2500.45
        },
        "ç°é‡‘æµé‡è¡¨": {
            "ç»è¥æ´»åŠ¨ç°é‡‘æµé‡å‡€é¢": 25.67,
            "æŠ•èµ„æ´»åŠ¨ç°é‡‘æµé‡å‡€é¢": -15.23,
            "ç­¹èµ„æ´»åŠ¨ç°é‡‘æµé‡å‡€é¢": -8.45
        },
        "å†å²æ•°æ®": {
            "2025": {"è¥ä¸šæ”¶å…¥": 573.88, "å‡€åˆ©æ¶¦": 11.04},
            "2024": {"è¥ä¸šæ”¶å…¥": 1511.39, "å‡€åˆ©æ¶¦": 36.11},
            "2023": {"è¥ä¸šæ”¶å…¥": 1420.56, "å‡€åˆ©æ¶¦": 32.45},
            "2022": {"è¥ä¸šæ”¶å…¥": 1280.23, "å‡€åˆ©æ¶¦": 28.67}
        }
    },
    
    "standard_financial_format": {
        "income_statement": {
            "revenue": 1000.0,
            "net_profit": 150.0,
            "operating_profit": 200.0
        },
        "balance_sheet": {
            "total_assets": 5000.0,
            "total_liabilities": 3000.0,
            "total_equity": 2000.0
        },
        "cash_flow": {
            "operating_cash_flow": 300.0,
            "investing_cash_flow": -100.0,
            "financing_cash_flow": -50.0
        },
        "historical_data": {
            "2024": {"revenue": 900.0, "net_profit": 120.0},
            "2023": {"revenue": 800.0, "net_profit": 100.0}
        }
    },
    
    "mixed_format": {
        "income_statement": {
            "revenue": 800.0,
            "å‡€åˆ©æ¶¦": 100.0,
            "è¥ä¸šæˆæœ¬": 600.0
        },
        "èµ„äº§è´Ÿå€ºè¡¨": {
            "æ€»èµ„äº§": 4000.0,
            "total_liabilities": 2500.0
        },
        "å†å²æ•°æ®": {
            "2024": {"è¥ä¸šæ”¶å…¥": 800.0, "å‡€åˆ©æ¶¦": 100.0},
            "2023": {"è¥ä¸šæ”¶å…¥": 750.0, "å‡€åˆ©æ¶¦": 90.0}
        }
    },
    
    "incomplete_data": {
        "åˆ©æ¶¦è¡¨": {
            "è¥ä¸šæ”¶å…¥": 500.0
            # ç¼ºå°‘å‡€åˆ©æ¶¦
        },
        # ç¼ºå°‘èµ„äº§è´Ÿå€ºè¡¨
        "å†å²æ•°æ®": {
            "2024": {"è¥ä¸šæ”¶å…¥": 500.0}
        }
    },
    
    "invalid_data": {
        "åˆ©æ¶¦è¡¨": {
            "è¥ä¸šæ”¶å…¥": "invalid_value",
            "å‡€åˆ©æ¶¦": None
        }
    }
}


class DataCleansingTestSuite:
    """æ•°æ®æ¸…æ´—æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        self.test_results = {
            'total_tests': 0,
            'passed_tests': 0,
            'failed_tests': 0,
            'test_details': []
        }
        
        # å¯¼å…¥æµ‹è¯•ç»„ä»¶
        try:
            from utu.data_engineering.validation_pipeline import DataValidationPipeline
            from utu.data_engineering.transform_pipeline import DataTransformPipeline
            from utu.data_engineering.quality_monitor import DataQualityMonitor
            from utu.agents.data_cleanser_agent import DataCleanserAgent
            from utu.tools.data_cleansing_toolkit import DataCleansingToolkit
            from utu.config import ToolkitConfig
            
            # åˆå§‹åŒ–ç»„ä»¶
            self.validation_pipeline = DataValidationPipeline()
            self.transform_pipeline = DataTransformPipeline()
            self.quality_monitor = DataQualityMonitor()
            self.cleanser_agent = DataCleanserAgent()
            
            # åˆå§‹åŒ–å·¥å…·åŒ…
            toolkit_config = ToolkitConfig(config={}, name="data_cleansing")
            self.cleansing_toolkit = DataCleansingToolkit(toolkit_config)
            
            logger.info("æ‰€æœ‰æµ‹è¯•ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"æµ‹è¯•ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    def record_test(self, test_name: str, passed: bool, details: str = "", duration: float = 0.0):
        """è®°å½•æµ‹è¯•ç»“æœ"""
        self.test_results['total_tests'] += 1
        if passed:
            self.test_results['passed_tests'] += 1
            status = "âœ… é€šè¿‡"
        else:
            self.test_results['failed_tests'] += 1
            status = "âŒ å¤±è´¥"
        
        self.test_results['test_details'].append({
            'name': test_name,
            'status': status,
            'details': details,
            'duration': duration
        })
        
        logger.info(f"{status}: {test_name}")
        if details:
            logger.info(f"  è¯¦æƒ…: {details}")
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("å¼€å§‹è¿è¡Œæ•°æ®æ¸…æ´—ç³»ç»Ÿæµ‹è¯•å¥—ä»¶")
        
        start_time = datetime.now()
        
        # å•å…ƒæµ‹è¯•
        self.test_validation_pipeline()
        self.test_transform_pipeline()
        self.test_quality_monitor()
        
        # é›†æˆæµ‹è¯•
        self.test_data_cleanser_agent()
        self.test_data_cleansing_toolkit()
        
        # ç«¯åˆ°ç«¯æµ‹è¯•
        self.test_end_to_end_processing()
        
        # æ€§èƒ½æµ‹è¯•
        self.test_performance()
        
        # è¾¹ç•Œæµ‹è¯•
        self.test_edge_cases()
        
        # é”™è¯¯å¤„ç†æµ‹è¯•
        self.test_error_handling()
        
        end_time = datetime.now()
        total_duration = (end_time - start_time).total_seconds()
        
        # è¾“å‡ºæµ‹è¯•ç»“æœæ‘˜è¦
        self.print_test_summary(total_duration)
    
    def test_validation_pipeline(self):
        """æµ‹è¯•æ•°æ®éªŒè¯ç®¡é“"""
        logger.info("\n=== æµ‹è¯•æ•°æ®éªŒè¯ç®¡é“ ===")
        
        test_cases = [
            ("chinese_financial_format", TEST_DATA_SAMPLES["chinese_financial_format"]),
            ("standard_financial_format", TEST_DATA_SAMPLES["standard_financial_format"]),
            ("incomplete_data", TEST_DATA_SAMPLES["incomplete_data"]),
            ("invalid_data", TEST_DATA_SAMPLES["invalid_data"])
        ]
        
        for case_name, test_data in test_cases:
            start_time = datetime.now()
            try:
                result = self.validation_pipeline.validate_financial_data_comprehensive(test_data)
                
                passed = (
                    hasattr(result, 'is_valid') and
                    hasattr(result, 'quality_score') and
                    hasattr(result, 'data_type')
                )
                
                details = f"æ•°æ®ç±»å‹: {result.data_type}, è´¨é‡åˆ†æ•°: {result.quality_score:.2f}"
                if result.errors:
                    details += f", é”™è¯¯æ•°: {len(result.errors)}"
                if result.warnings:
                    details += f", è­¦å‘Šæ•°: {len(result.warnings)}"
                
                duration = (datetime.now() - start_time).total_seconds()
                self.record_test(f"éªŒè¯ç®¡é“_{case_name}", passed, details, duration)
                
            except Exception as e:
                duration = (datetime.now() - start_time).total_seconds()
                self.record_test(f"éªŒè¯ç®¡é“_{case_name}", False, f"å¼‚å¸¸: {str(e)}", duration)
    
    def test_transform_pipeline(self):
        """æµ‹è¯•æ•°æ®è½¬æ¢ç®¡é“"""
        logger.info("\n=== æµ‹è¯•æ•°æ®è½¬æ¢ç®¡é“ ===")
        
        test_cases = [
            ("chinese_to_standard", TEST_DATA_SAMPLES["chinese_financial_format"]),
            ("standard_format", TEST_DATA_SAMPLES["standard_financial_format"]),
            ("mixed_format", TEST_DATA_SAMPLES["mixed_format"])
        ]
        
        target_formats = ["data_analysis_agent_compatible", "chart_generator_compatible"]
        
        for case_name, test_data in test_cases:
            for target_format in target_formats:
                start_time = datetime.now()
                try:
                    result = self.transform_pipeline.transform_financial_data(
                        test_data, target_format
                    )
                    
                    passed = result.success and result.transformed_data is not None
                    
                    details = f"ç›®æ ‡æ ¼å¼: {target_format}, è½¬æ¢ç‡: {result.conversion_rate:.1f}%"
                    if result.fields_transformed > 0:
                        details += f", å­—æ®µè½¬æ¢: {result.fields_transformed}"
                    
                    duration = (datetime.now() - start_time).total_seconds()
                    self.record_test(
                        f"è½¬æ¢ç®¡é“_{case_name}_{target_format}", 
                        passed, 
                        details, 
                        duration
                    )
                    
                except Exception as e:
                    duration = (datetime.now() - start_time).total_seconds()
                    self.record_test(
                        f"è½¬æ¢ç®¡é“_{case_name}_{target_format}", 
                        False, 
                        f"å¼‚å¸¸: {str(e)}", 
                        duration
                    )
    
    def test_quality_monitor(self):
        """æµ‹è¯•æ•°æ®è´¨é‡ç›‘æ§å™¨"""
        logger.info("\n=== æµ‹è¯•æ•°æ®è´¨é‡ç›‘æ§å™¨ ===")
        
        test_cases = [
            ("good_quality_data", TEST_DATA_SAMPLES["chinese_financial_format"]),
            ("standard_data", TEST_DATA_SAMPLES["standard_financial_format"]),
            ("incomplete_data", TEST_DATA_SAMPLES["incomplete_data"])
        ]
        
        for case_name, test_data in test_cases:
            start_time = datetime.now()
            try:
                report = self.quality_monitor.assess_data_quality(test_data)
                
                passed = (
                    hasattr(report, 'metrics') and
                    hasattr(report, 'quality_level') and
                    report.metrics.overall_score >= 0
                )
                
                details = f"è´¨é‡ç­‰çº§: {report.metrics.quality_level}, åˆ†æ•°: {report.metrics.overall_score:.2f}"
                details += f", é—®é¢˜æ•°: {len(report.issues)}"
                
                duration = (datetime.now() - start_time).total_seconds()
                self.record_test(f"è´¨é‡ç›‘æ§_{case_name}", passed, details, duration)
                
            except Exception as e:
                duration = (datetime.now() - start_time).total_seconds()
                self.record_test(f"è´¨é‡ç›‘æ§_{case_name}", False, f"å¼‚å¸¸: {str(e)}", duration)
    
    def test_data_cleanser_agent(self):
        """æµ‹è¯•æ•°æ®æ¸…æ´—æ™ºèƒ½ä½“"""
        logger.info("\n=== æµ‹è¯•æ•°æ®æ¸…æ´—æ™ºèƒ½ä½“ ===")
        
        test_cases = [
            ("chinese_data_cleansing", TEST_DATA_SAMPLES["chinese_financial_format"]),
            ("standard_data_cleansing", TEST_DATA_SAMPLES["standard_financial_format"]),
            ("mixed_data_cleansing", TEST_DATA_SAMPLES["mixed_format"])
        ]
        
        for case_name, test_data in test_cases:
            start_time = datetime.now()
            try:
                result = asyncio.run(
                    self.cleanser_agent.cleanse_financial_data(test_data)
                )
                
                passed = result.get('success', False) and 'cleansed_data' in result
                
                details = f"è´¨é‡åˆ†æ•°: {result.get('quality_score', 0):.2f}"
                if result.get('issues_found', 0) > 0:
                    details += f", é—®é¢˜æ•°: {result['issues_found']}"
                if result.get('transformation_summary'):
                    summary = result['transformation_summary']
                    details += f", è½¬æ¢å­—æ®µ: {summary.get('fields_transformed', 0)}"
                
                duration = (datetime.now() - start_time).total_seconds()
                self.record_test(f"æ™ºèƒ½ä½“_{case_name}", passed, details, duration)
                
            except Exception as e:
                duration = (datetime.now() - start_time).total_seconds()
                self.record_test(f"æ™ºèƒ½ä½“_{case_name}", False, f"å¼‚å¸¸: {str(e)}", duration)
    
    def test_data_cleansing_toolkit(self):
        """æµ‹è¯•æ•°æ®æ¸…æ´—å·¥å…·é›†"""
        logger.info("\n=== æµ‹è¯•æ•°æ®æ¸…æ´—å·¥å…·é›† ===")
        
        test_cases = [
            ("cleanse_financial_data", TEST_DATA_SAMPLES["chinese_financial_format"]),
            ("quick_cleanse_data", TEST_DATA_SAMPLES["mixed_format"]),
            ("validate_data_format", TEST_DATA_SAMPLES["standard_financial_format"])
        ]
        
        for case_name, test_data in test_cases:
            start_time = datetime.now()
            try:
                if case_name == "cleanse_financial_data":
                    result = self.cleansing_toolkit.cleanse_financial_data(test_data)
                    passed = result.get('success', False)
                    details = f"è´¨é‡åˆ†æ•°: {result.get('quality_score', 0):.2f}"
                    
                elif case_name == "quick_cleanse_data":
                    result = self.cleansing_toolkit.quick_cleanse_data(test_data)
                    passed = result.get('success', False)
                    details = f"è´¨é‡ç­‰çº§: {result.get('quality_level', 'unknown')}"
                    
                elif case_name == "validate_data_format":
                    result = self.cleansing_toolkit.validate_data_format(test_data)
                    passed = result.get('success', False)
                    details = f"éªŒè¯é€šè¿‡: {result.get('success', False)}"
                
                duration = (datetime.now() - start_time).total_seconds()
                self.record_test(f"å·¥å…·é›†_{case_name}", passed, details, duration)
                
            except Exception as e:
                duration = (datetime.now() - start_time).total_seconds()
                self.record_test(f"å·¥å…·é›†_{case_name}", False, f"å¼‚å¸¸: {str(e)}", duration)
    
    def test_end_to_end_processing(self):
        """æµ‹è¯•ç«¯åˆ°ç«¯å¤„ç†"""
        logger.info("\n=== æµ‹è¯•ç«¯åˆ°ç«¯å¤„ç† ===")
        
        test_data = TEST_DATA_SAMPLES["chinese_financial_format"]
        start_time = datetime.now()
        
        try:
            # å®Œæ•´å¤„ç†æµç¨‹
            # 1. éªŒè¯
            validation_result = self.validation_pipeline.validate_financial_data_comprehensive(test_data)
            
            # 2. è½¬æ¢
            transform_result = self.transform_pipeline.transform_financial_data(
                test_data, "data_analysis_agent_compatible"
            )
            
            # 3. è´¨é‡è¯„ä¼°
            quality_report = self.quality_monitor.assess_data_quality(
                transform_result.transformed_data or {}
            )
            
            # 4. æ™ºèƒ½ä½“æ¸…æ´—
            cleansing_result = asyncio.run(
                self.cleanser_agent.cleanse_financial_data(test_data)
            )
            
            # æ£€æŸ¥æ‰€æœ‰æ­¥éª¤éƒ½æˆåŠŸ
            passed = (
                validation_result.is_valid and
                transform_result.success and
                quality_report.metrics.overall_score > 0 and
                cleansing_result.get('success', False)
            )
            
            details = f"éªŒè¯: {validation_result.is_valid}, è½¬æ¢: {transform_result.success}"
            details += f", è´¨é‡: {quality_report.metrics.overall_score:.2f}"
            details += f", æ¸…æ´—: {cleansing_result.get('success', False)}"
            
            duration = (datetime.now() - start_time).total_seconds()
            self.record_test("ç«¯åˆ°ç«¯å¤„ç†", passed, details, duration)
            
        except Exception as e:
            duration = (datetime.now() - start_time).total_seconds()
            self.record_test("ç«¯åˆ°ç«¯å¤„ç†", False, f"å¼‚å¸¸: {str(e)}", duration)
    
    def test_performance(self):
        """æµ‹è¯•æ€§èƒ½"""
        logger.info("\n=== æµ‹è¯•æ€§èƒ½ ===")
        
        # æ€§èƒ½æµ‹è¯•ç”¨ä¾‹
        performance_cases = [
            ("å¤§æ•°æ®é›†å¤„ç†", self._generate_large_dataset(1000)),
            ("ä¸­ç­‰æ•°æ®é›†å¤„ç†", self._generate_large_dataset(100)),
            ("å°æ•°æ®é›†å¤„ç†", self._generate_large_dataset(10))
        ]
        
        for case_name, test_data in performance_cases:
            start_time = datetime.now()
            try:
                result = asyncio.run(
                    self.cleanser_agent.cleanse_financial_data(test_data)
                )
                
                duration = (datetime.now() - start_time).total_seconds()
                
                # æ€§èƒ½è¦æ±‚ï¼šå¤„ç†æ—¶é—´ä¸è¶…è¿‡5ç§’
                passed = result.get('success', False) and duration < 5.0
                
                details = f"å¤„ç†æ—¶é—´: {duration:.3f}ç§’, æ•°æ®å¤§å°: {len(json.dumps(test_data))}å­—ç¬¦"
                
                self.record_test(f"æ€§èƒ½_{case_name}", passed, details, duration)
                
            except Exception as e:
                duration = (datetime.now() - start_time).total_seconds()
                self.record_test(f"æ€§èƒ½_{case_name}", False, f"å¼‚å¸¸: {str(e)}", duration)
    
    def test_edge_cases(self):
        """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
        logger.info("\n=== æµ‹è¯•è¾¹ç•Œæƒ…å†µ ===")
        
        edge_cases = [
            ("ç©ºæ•°æ®", {}),
            ("åªæœ‰ä¸­æ–‡é”®å", {"åˆ©æ¶¦è¡¨": {"è¥ä¸šæ”¶å…¥": 100}}),
            ("åªæœ‰è‹±æ–‡é”®å", {"income_statement": {"revenue": 100}}),
            ("å­—ç¬¦ä¸²æ•°å€¼", {"åˆ©æ¶¦è¡¨": {"è¥ä¸šæ”¶å…¥": "100.5", "å‡€åˆ©æ¶¦": "50.2"}}),
            ("è´Ÿæ•°å€¼", {"åˆ©æ¶¦è¡¨": {"è¥ä¸šæ”¶å…¥": 1000, "å‡€åˆ©æ¶¦": -50}}),
            ("é›¶å€¼", {"åˆ©æ¶¦è¡¨": {"è¥ä¸šæ”¶å…¥": 0, "å‡€åˆ©æ¶¦": 0}}),
            ("æå¤§å€¼", {"åˆ©æ¶¦è¡¨": {"è¥ä¸šæ”¶å…¥": 1e15, "å‡€åˆ©æ¶¦": 1e12}}),
            ("æå°å€¼", {"åˆ©æ¶¦è¡¨": {"è¥ä¸šæ”¶å…¥": 0.001, "å‡€åˆ©æ¶¦": 0.0001}})
        ]
        
        for case_name, test_data in edge_cases:
            start_time = datetime.now()
            try:
                result = self.cleansing_toolkit.quick_cleanse_data(test_data)
                
                passed = result.get('success', False)
                details = f"å¤„ç†ç»“æœ: {'æˆåŠŸ' if passed else 'å¤±è´¥'}"
                
                duration = (datetime.now() - start_time).total_seconds()
                self.record_test(f"è¾¹ç•Œ_{case_name}", passed, details, duration)
                
            except Exception as e:
                duration = (datetime.now() - start_time).total_seconds()
                self.record_test(f"è¾¹ç•Œ_{case_name}", False, f"å¼‚å¸¸: {str(e)}", duration)
    
    def test_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        logger.info("\n=== æµ‹è¯•é”™è¯¯å¤„ç† ===")
        
        error_cases = [
            ("æ— æ•ˆJSONå­—ç¬¦ä¸²", "{invalid json string"),
            ("éå­—å…¸æ•°æ®", [1, 2, 3]),
            ("Noneå€¼", None),
            ("æ— é™å¤§å€¼", {"åˆ©æ¶¦è¡¨": {"è¥ä¸šæ”¶å…¥": float('inf')}}),
            ("NaNå€¼", {"åˆ©æ¶¦è¡¨": {"è¥ä¸šæ”¶å…¥": float('nan')}})
        ]
        
        for case_name, test_data in error_cases:
            start_time = datetime.now()
            try:
                result = self.cleansing_toolkit.validate_data_format(test_data)
                
                # é”™è¯¯æƒ…å†µä¸‹åº”è¯¥è¿”å›success: Falseä½†æœ‰æœ‰æ„ä¹‰çš„é”™è¯¯ä¿¡æ¯
                passed = not result.get('success', True) and 'error' in result
                
                details = f"æ­£ç¡®å¤„ç†é”™è¯¯: {passed}"
                if 'error' in result:
                    details += f", é”™è¯¯ä¿¡æ¯: {result['error'][:50]}..."
                
                duration = (datetime.now() - start_time).total_seconds()
                self.record_test(f"é”™è¯¯å¤„ç†_{case_name}", passed, details, duration)
                
            except Exception as e:
                duration = (datetime.now() - start_time).total_seconds()
                self.record_test(f"é”™è¯¯å¤„ç†_{case_name}", False, f"å¼‚å¸¸: {str(e)}", duration)
    
    def _generate_large_dataset(self, size: int) -> Dict[str, Any]:
        """ç”Ÿæˆå¤§å‹æ•°æ®é›†ç”¨äºæ€§èƒ½æµ‹è¯•"""
        data = {
            "åˆ©æ¶¦è¡¨": {},
            "èµ„äº§è´Ÿå€ºè¡¨": {},
            "ç°é‡‘æµé‡è¡¨": {},
            "å†å²_data": {}
        }
        
        # ç”Ÿæˆå†å²æ•°æ®
        for i in range(size):
            year = 2020 + (i % 5)
            data["å†å²æ•°æ®"][str(year)] = {
                "è¥ä¸šæ”¶å…¥": 1000 + i * 10,
                "å‡€åˆ©æ¶¦": 100 + i,
                "è¥ä¸šæˆæœ¬": 800 + i * 8
            }
        
        return data
    
    def print_test_summary(self, total_duration: float):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        logger.info("\n" + "="*60)
        logger.info("æµ‹è¯•æ‘˜è¦")
        logger.info("="*60)
        
        total = self.test_results['total_tests']
        passed = self.test_results['passed_tests']
        failed = self.test_results['failed_tests']
        success_rate = (passed / total * 100) if total > 0 else 0
        
        logger.info(f"æ€»æµ‹è¯•æ•°: {total}")
        logger.info(f"é€šè¿‡: {passed}")
        logger.info(f"å¤±è´¥: {failed}")
        logger.info(f"æˆåŠŸç‡: {success_rate:.1f}%")
        logger.info(f"æ€»è€—æ—¶: {total_duration:.3f}ç§’")
        
        if failed > 0:
            logger.info("\nå¤±è´¥çš„æµ‹è¯•:")
            for test in self.test_results['test_details']:
                if "å¤±è´¥" in test['status']:
                    logger.info(f"   - {test['name']}: {test['details']}")
        
        logger.info("\næ‰€æœ‰æµ‹è¯•è¯¦æƒ…:")
        for test in self.test_results['test_details']:
            logger.info(f"   {test['status']}: {test['name']} ({test['duration']:.3f}s)")
        
        logger.info("="*60)
        
        # ä¿å­˜æµ‹è¯•æŠ¥å‘Š
        self.save_test_report(total_duration, success_rate)
    
    def save_test_report(self, total_duration: float, success_rate: float):
        """ä¿å­˜æµ‹è¯•æŠ¥å‘Š"""
        try:
            report = {
                "test_summary": {
                    "total_tests": self.test_results['total_tests'],
                    "passed_tests": self.test_results['passed_tests'],
                    "failed_tests": self.test_results['failed_tests'],
                    "success_rate": success_rate,
                    "total_duration": total_duration,
                    "test_time": datetime.now().isoformat()
                },
                "test_details": self.test_results['test_details']
            }
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            report_file = project_root / "test_data_cleansing_report.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            logger.info(f"æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜æµ‹è¯•æŠ¥å‘Šå¤±è´¥: {str(e)}")


def main():
    """ä¸»å‡½æ•°"""
    print("æ•°æ®æ¸…æ´—ç³»ç»Ÿç‹¬ç«‹æµ‹è¯•å¥—ä»¶")
    print("=" * 50)
    
    try:
        # åˆ›å»ºæµ‹è¯•å¥—ä»¶
        test_suite = DataCleansingTestSuite()
        
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        test_suite.run_all_tests()
        
        # æ£€æŸ¥ç»“æœ
        if test_suite.test_results['failed_tests'] == 0:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®æ¸…æ´—ç³»ç»ŸåŠŸèƒ½æ­£å¸¸ã€‚")
            return True
        else:
            print(f"\nâš ï¸ æœ‰ {test_suite.test_results['failed_tests']} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é—®é¢˜ã€‚")
            return False
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¥—ä»¶æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)